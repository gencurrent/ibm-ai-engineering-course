{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer-graded Assignment: Build a Regression Model in Keras\n",
    "The lab is split into 2 main parts:\n",
    "1. Data preparation. Includes reading the dataset, preparing its values and normalizing it\n",
    "2. Part A, B, C, D according to the assessment tasks\n",
    "\n",
    "Requirements:\n",
    "0. Python 3.11.1\n",
    "1. Jupyter core\n",
    "2. Jupyter lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download / read the data\n",
    "2. Split the data into the train and test sets\n",
    "3. Define a function to generate a Keras model for the dataset\n",
    "4. Fit and train the model\n",
    "5. Test the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the libraries\n",
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install matplotlib\n",
    "# %pip install scikit-learn\n",
    "# %pip install tensorflow\n",
    "# %pip install keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math and data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "concrete_data = pd.read_csv(\"concrete_data.csv\")\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into predictors and target\n",
    "\n",
    "predictors = concrete_data[concrete_data.columns[concrete_data.columns != \"Strength\"]]\n",
    "target = concrete_data[\"Strength\"]\n",
    "normalized_predictors = (predictors - predictors.mean()) / predictors.std()\n",
    "\n",
    "assert type(predictors) is pd.DataFrame\n",
    "assert type(target) is pd.Series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model generation functions\n",
    "1. The Part A,B,C of 1 10-nodes ReLU hidden layer model yielding function\n",
    "1. The Part D of 3 10-nodes ReLU hidden layers model yielding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network model generation function\n",
    "def generate_model_ABC(n_cols: int, ):\n",
    "    \"\"\"\n",
    "    Generate model for the assessments parts A, B, C\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(10, activation=\"relu\", input_shape=(n_cols,))\n",
    "    )\n",
    "    model.add(\n",
    "        Dense(1)\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\",)\n",
    "\n",
    "    return model\n",
    "\n",
    "def generate_model_D(n_cols: int, ):\n",
    "    \"\"\"\n",
    "    Generate model for the assessment part D\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(10, activation=\"relu\", input_shape=(n_cols,))\n",
    "    )\n",
    "    model.add(\n",
    "        Dense(10, activation=\"relu\"),\n",
    "    )\n",
    "    model.add(\n",
    "        Dense(10, activation=\"relu\"),\n",
    "    )\n",
    "    model.add(\n",
    "        Dense(1)\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\",)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions(\n",
    "        x_train: np.ndarray,\n",
    "        x_test: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        model: keras.Model,\n",
    "        epochs: int,\n",
    "        verbose: int = 0,\n",
    "        ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: the model to train\n",
    "        n_cols: number of columns which determine the input shape of the model\n",
    "    Return:\n",
    "        float: the Mean Squared Error value of the model predictions\n",
    "            against the original test dataset\n",
    "    \"\"\"\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, epochs=epochs, verbose=verbose)\n",
    "    # Yield the predictions\n",
    "    predictions = model.predict(x_test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate for N times\n",
    "from typing import Tuple\n",
    "\n",
    "def generate_model_on_data(\n",
    "        predictors: pd.DataFrame,\n",
    "        target: pd.Series,\n",
    "        epochs_number: int,\n",
    "        model_generation_function,\n",
    "        N: int = 50,\n",
    "        verbose: int = 0,\n",
    "    ) -> Tuple[np.ndarray, keras.Model]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        predictors (pd.DataFrame): input data (X_0, X_1, ..., X_n)\n",
    "        target (pd.DataFrame): labels according to the predictors (Y)\n",
    "        epochs_number (int): number of model training optimization iterations\n",
    "        model_generation_function (Callable): the function to generate a model. Either generate_model_ABC or generate_model_D\n",
    "        N (int) = 50: constant number of training repetitions\n",
    "        verbose (int) = 0: the training verbosity\n",
    "    Return:\n",
    "        np.ndarray: array of MSE for each iteration\n",
    "    \"\"\"\n",
    "    mse_list = []\n",
    "\n",
    "    for idx in range(N):\n",
    "        print(f\"Training iteration #{idx}/{N}\")\n",
    "        x_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=idx)\n",
    "        n_cols = x_train.shape[1]\n",
    "        model = model_generation_function(n_cols)\n",
    "        predictions = get_model_predictions(\n",
    "            x_train, x_test, y_train,\n",
    "            model=model,\n",
    "            epochs=epochs_number,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        mse_list.append(mse)\n",
    "        \n",
    "    mse_array = np.array(mse_list)\n",
    "    assert mse_array.shape[0] == N\n",
    "    return mse_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MSE report function\n",
    "def print_mse_report(mse_array: np.ndarray):\n",
    "    # Report the mean and the standard deviation of the mean squared errors.\n",
    "    print(f\"The MSE mean value is {mse_array.mean()}\")\n",
    "    print(f\"The MSE standard deviation is {mse_array.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Build a baseline model (5 marks) \n",
    "\n",
    "Use the Keras library to build a neural network with the following:\n",
    "\n",
    "- One hidden layer of 10 nodes, and a ReLU activation function\n",
    "\n",
    "- Use the adam optimizer and the mean squared error  as the loss function.\n",
    "\n",
    "1. Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the train_test_split\n",
    "\n",
    "helper function from Scikit-learn.\n",
    "\n",
    "2. Train the model on the training data using 50 epochs.\n",
    "\n",
    "3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
    "\n",
    "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
    "\n",
    "5. Report the mean and the standard deviation of the mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A MSEs\n",
    "part_A_mse_array  = generate_model_on_data(\n",
    "    predictors=predictors,\n",
    "    target=target,\n",
    "    epochs_number=50,\n",
    "    model_generation_function=generate_model_ABC,\n",
    "    N=50,\n",
    "    verbose=0,\n",
    ")\n",
    "print(part_A_mse_array)\n",
    "print_mse_report(part_A_mse_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion on Part A\n",
    "The MSE mean value is 406.5074  \n",
    "The MSE standard deviation is 393.3563  \n",
    "The mean squared error (MSE) is significantly high which does not seem possible to use on real datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Normalize the data (5 marks) \n",
    "\n",
    "Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step A?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part B MSEs\n",
    "part_B_mse_array = generate_model_on_data(\n",
    "    predictors=normalized_predictors,   # Use the normalized predictors\n",
    "    target=target,\n",
    "    epochs_number=50,\n",
    "    model_generation_function=generate_model_ABC,\n",
    "    N=50,\n",
    "    verbose=0,\n",
    ")\n",
    "print_mse_report(part_B_mse_array)\n",
    "\n",
    "print(f\"The mean MSE difference between parts B and A is {part_B_mse_array.mean() - part_A_mse_array.mean()}\")\n",
    "print(f\"The mean MSE % increase between parts B and A is {(1 - part_B_mse_array.mean() / part_A_mse_array.mean()) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion on Part B\n",
    "The MSE mean value has dropped from 406.5074 to 398.9995 - the decrease rate is almost constant  \n",
    "The MSE standard deviation has dropped from 393.3563 to 126.9637 which is nearly 70% better \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Increate the number of epochs (5 marks)\n",
    "\n",
    "Repeat Part B but use 100 epochs this time for training.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part C MSEs\n",
    "part_C_mse_array = generate_model_on_data(\n",
    "    predictors=normalized_predictors,\n",
    "    target=target,\n",
    "    epochs_number=100,  # Increase the number of epochs from 50 to 100\n",
    "    model_generation_function=generate_model_ABC,\n",
    "    N=50,\n",
    "    verbose=0,\n",
    ")\n",
    "print_mse_report(part_C_mse_array)\n",
    "\n",
    "print(f\"The mean MSE difference between parts C and B is {part_C_mse_array.mean() - part_B_mse_array.mean()}\")\n",
    "print(f\"The mean MSE % increase between parts C and B is {(1 - part_C_mse_array.mean() / part_B_mse_array.mean()) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion on Part C\n",
    "The MSE mean value has dropped from 398.99 to 167.29 - the 58.07% decrease is significant  \n",
    "The MSE standard deviation has dropped from 126.96 to just 16.90 which is just 13.3% of the Part B deviation. The change is indcredibly high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Increase the number of hidden layers (5 marks)\n",
    "\n",
    "Repeat part B but use a neural network with the following instead:\n",
    "\n",
    "- Three hidden layers, each of 10 nodes and ReLU activation function.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part D MSEs\n",
    "part_D_mse_array = generate_model_on_data(\n",
    "    predictors=normalized_predictors,\n",
    "    target=target,\n",
    "    epochs_number=100,\n",
    "    model_generation_function=generate_model_D, # Use the 3 hidden layers model instead of 1\n",
    "    N=50,\n",
    "    verbose=0,\n",
    ")\n",
    "print_mse_report(part_D_mse_array)\n",
    "\n",
    "print(f\"The mean MSE difference between parts D and C is {part_D_mse_array.mean() - part_C_mse_array.mean()}\")\n",
    "print(f\"The mean MSE % increase between parts D and C is {(1 - part_D_mse_array.mean() / part_C_mse_array.mean()) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion on Part D\n",
    "The MSE mean value has dropped from 167.29 to just 91.06 - the 45.5% decrease is the second pivotal difference  \n",
    "The MSE standard deviation has increased from 16.9 to 24.91 - a 47.3% increase. However, in terms of lower MSE it can be counted as a positive factor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course-ibm-ai-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
